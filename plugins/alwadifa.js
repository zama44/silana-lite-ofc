//plugin by @noureddine_ouafy
//recode by Obito owner ( fix the scrape and make it support button) ðŸ§ 
//scraped by my friend Malik

import cheerio from 'cheerio';
import fetch from 'node-fetch';

let handler = async (m, { conn, text }) => {
  const listOptions = ["all", "download"];
  const [feature, inputs] = text ? text.split("|") : ["all"];

  if (!listOptions.includes(feature)) {
    return conn.reply(
      m.chat,
      "âŒ *Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø®ÙŠØ§Ø± ØµØ§Ù„Ø­* \n\n*Ø§Ù„Ø¥Ø®ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:* \n" +
        listOptions.map((v) => `â—‹ ${v}`).join("\n"),
      m
    );
  }

  if (feature === "all") {
    await conn.reply(m.chat, "â³ *Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù... Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±* ðŸ”", m);
    try {
      let res = await scrapeData();

      const buttons = res.map((item, index) => ({
        header: "",
        title: item.title,
        description: `ðŸ“œ Views: ${item.views}`,
        id: `.alwadifa download|${index}`,
      }));

      conn.relayMessage(m.chat, {
        viewOnceMessage: {
          message: {
            interactiveMessage: {
              header: {
                title: "ðŸ“‹ *Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨*",
              },
              body: {
                text: "ðŸ” Ø­Ø¯Ø¯ ÙˆØ¸ÙŠÙØ© Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„ ÙˆØ§Ù„ØªØ³Ø¬ÙŠÙ„",
              },
              nativeFlowMessage: {
                buttons: [
                  {
                    name: "single_select",
                    buttonParamsJson: JSON.stringify({
                      title: "ðŸ”Ž Ø§Ù„ÙˆØ¸Ø§Ø¦Ù",
                      sections: [
                        {
                          title: "ðŸ“œ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ØªØ§Ø­Ø©",
                          highlight_label: "Silana Ai",
                          rows: buttons,
                        },
                      ],
                    }),
                    messageParamsJson: "",
                  },
                ],
              },
            },
          },
        },
      }, {});
    } catch (e) {
      console.error(e);
      await conn.reply(m.chat, "âŒ *An error occurred while fetching jobs!*", m);
    }
  }

  if (feature === "download") {
    if (!inputs) return conn.reply(m.chat, "âŒ *ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø±Ù‚Ù… Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø£Ùˆ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©!*", m);
    await conn.reply(m.chat, "â³ *Ù‚Ø±Ø§Ø¡Ø© ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙˆØ¸ÙŠÙØ©... Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±* ðŸ”", m);
    try {
      let res = await scrapeData();
      let url;

      if (/^\d+$/.test(inputs)) {
        url = res[parseInt(inputs)].link;
      } else {
        url = inputs;
      }

      let paragraphs = await getParagraphsFromURL(url);
      const content = paragraphs.length
        ? paragraphs.join("\n")
        : "âŒ *No content found for this job!*";

      await conn.reply(m.chat, `ðŸ” *Job Details:*\n\nðŸ“œ ${content}`, m);
    } catch (e) {
      console.error(e);
      await conn.reply(m.chat, "âŒ *An error occurred while reading the details!*", m);
    }
  }
};

handler.help = ["alwadifa"];
handler.tags = ["morocco"];
handler.command = /^alwadifa$/i;
handler.limit = true;
export default handler;

/* Edited source for you */
async function scrapeData() {
  const url = "http://alwadifa-maroc.com/";
  const response = await fetch(url);
  const html = await response.text();
  const $ = cheerio.load(html);
  const items = [];

  $(".bloc-content").each((index, element) => {
    const link = $(element).find("a:first-child").attr("href");
    const title = $(element).find("a:first-child").text().trim();
    const image = $(element).find("img").attr("src");
    const [info, views, comments] = $(element)
      .find("li")
      .map((i, el) => $(el).text().trim())
      .get();

    items.push({
      title,
      link: link.startsWith("/") ? `${new URL(url).origin}${link}` : link,
      image: image.startsWith("/") ? `${new URL(url).origin}${image}` : image,
      info,
      views,
      comments,
    });
  });

  return items;
}

async function getParagraphsFromURL(url) {
  try {
    const response = await fetch(url);
    const data = await response.text();
    const $ = cheerio.load(data);
    const paragraphs = $("p")
      .map((index, element) => $(element).text().trim())
      .get();

    return paragraphs;
  } catch (error) {
    console.error("Error fetching or parsing the page:", error);
    return [];
  }
}
